{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d684172-4b94-42cf-bda2-e11952420d86",
      "metadata": {
        "id": "4d684172-4b94-42cf-bda2-e11952420d86"
      },
      "source": [
        "# Homework 10\n",
        "\n",
        "Collin Stewart  \n",
        "https://github.com/collings512/BIOS512_Collin_Stewart\n",
        "\n",
        "#### Course Notes\n",
        "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
        "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
        "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"httr\")\n",
        "install.packages(\"tokenizers\")\n",
        "install.packages(\"dplyr\")\n",
        "install.packages(\"tidyverse\")\n",
        "install.packages(\"stringr\")\n",
        "\n",
        "library(httr)\n",
        "library(tokenizers)\n",
        "library(dplyr)\n",
        "library(tidyverse)\n",
        "library(stringr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8MpWNnlqv-N",
        "outputId": "55d33a69-6be1-49a5-da73-bd75068c3e4e"
      },
      "id": "E8MpWNnlqv-N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘SnowballC’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n",
            "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
            "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.1     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.6\n",
            "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 4.0.1     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.6.0\n",
            "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.3.0\n",
            "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
            "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
            "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d839a5ba-62f4-4699-baea-018afda70786",
      "metadata": {
        "id": "d839a5ba-62f4-4699-baea-018afda70786"
      },
      "source": [
        "## Question 1\n",
        "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
      "metadata": {
        "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49"
      },
      "source": [
        "#### a) Make a function to tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_text <- function(text) {\n",
        "  tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "M4tzIQrDpvdA"
      },
      "id": "M4tzIQrDpvdA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "86145513-294b-4894-a02c-8ae60e2c616e",
      "metadata": {
        "id": "86145513-294b-4894-a02c-8ae60e2c616e"
      },
      "source": [
        "#### b) Make a function generate keys for ngrams."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key_from <- function(ngram, sep = \"\\x1f\") {\n",
        "  paste(ngram, collapse=sep)\n",
        "}"
      ],
      "metadata": {
        "id": "dHIQgP2mriOp"
      },
      "id": "dHIQgP2mriOp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "52988c2c-b230-467f-b519-72bc85b93b43",
      "metadata": {
        "id": "52988c2c-b230-467f-b519-72bc85b93b43"
      },
      "source": [
        "#### c) Make a function to build an ngram table."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
        "  if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
        "  tbl <- new.env(parent = emptyenv())\n",
        "  for (i in seq_len(length(tokens) - n + 1L)) {\n",
        "    ngram <- tokens[i:(i + n - 2L)]\n",
        "    next_word <- tokens[i + n - 1L]\n",
        "    key <- paste(ngram, collapse = sep)\n",
        "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "    if(next_word %in% names(counts)) {\n",
        "      counts[[next_word]] <- counts[[next_word]] + 1L\n",
        "    } else {\n",
        "        counts[[next_word]] <- 1L\n",
        "    }\n",
        "    tbl[[key]] <- counts\n",
        "  }\n",
        "  tbl\n",
        "}"
      ],
      "metadata": {
        "id": "HotFkjyLrq2O"
      },
      "id": "HotFkjyLrq2O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ca6db37-abce-4705-9784-e1b898174f00",
      "metadata": {
        "id": "1ca6db37-abce-4705-9784-e1b898174f00"
      },
      "source": [
        "#### d) Function to digest the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_text <- function(text, n) {\n",
        "  tokens <- tokenize_text(text)\n",
        "  build_ngram_table(tokens, n)\n",
        "}"
      ],
      "metadata": {
        "id": "nKBPKN9xstFa"
      },
      "id": "nKBPKN9xstFa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
      "metadata": {
        "id": "53fff313-0f13-479b-94df-7588c19fdd3d"
      },
      "source": [
        "#### e) Function to digest the url."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_url <- function(url, n) {\n",
        "  res <- httr::GET(url)\n",
        "  txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
        "  digest_text(txt,n)\n",
        "}"
      ],
      "metadata": {
        "id": "p9J9qACLs18N"
      },
      "id": "p9J9qACLs18N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
      "metadata": {
        "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a"
      },
      "source": [
        "#### f) Function that gives random start."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_start <- function(tbl, sep = \"\\x1f\") {\n",
        "  keys <- ls(envir = tbl, all.names=TRUE)\n",
        "  if(length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
        "  picked <- sample(keys, 1)\n",
        "  strsplit(picked, sep, fixed=TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "2Os1lxaVtFrL"
      },
      "id": "2Os1lxaVtFrL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
      "metadata": {
        "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f"
      },
      "source": [
        "#### g) Function to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word <- function(tbl, ngram, sep=\"\\x1f\") {\n",
        "  key <- paste(ngram, collapse = sep)\n",
        "  counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "  if (length(counts) == 0) return(NA_character_)\n",
        "  sample(names(counts), size=1, prob=as.numeric(counts))\n",
        "}"
      ],
      "metadata": {
        "id": "POPRwEq0tcxj"
      },
      "id": "POPRwEq0tcxj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "347f4002-4932-42c4-a4af-8689293a5857",
      "metadata": {
        "id": "347f4002-4932-42c4-a4af-8689293a5857"
      },
      "source": [
        "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
        "  force(tbl); n <- as.integer(n); force(sep)\n",
        "  function(start_words = NULL, length = 10L) {\n",
        "    if ((is.null(start_words)) || length(start_words) !=n - 1L) {\n",
        "      start_words <- random_start(tbl, sep=sep)\n",
        "    }\n",
        "    word_sequence <- start_words\n",
        "    for (i in seq_len(max(0L, length - length(start_words)))) {\n",
        "      ngram <- tail(word_sequence, n - 1L)\n",
        "      next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
        "      if(is.na(next_word)) break\n",
        "      word_sequence <- c(word_sequence, next_word)\n",
        "    }\n",
        "    paste(word_sequence, collapse= \" \")\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "CMMw9Yl6t34U"
      },
      "id": "CMMw9Yl6t34U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
      "metadata": {
        "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554"
      },
      "source": [
        "## Question 2\n",
        "#### For this question, set `seed=2025`.\n",
        "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2025)\n",
        "\n",
        "urlques2a <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
        "tblques2a <- digest_url(urlques2a, n=3)\n",
        "genques2a <- make_ngram_generator(tblques2a, n=3)\n",
        "\n",
        "\n",
        "print(genques2a(start_words = c(\"the\", \"king\"),length=15))\n",
        "\n",
        "set.seed(2025)\n",
        "print(genques2a(length=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m5EoTQMu3MZ",
        "outputId": "06637d54-01c7-4a19-bf87-710593c94a6a"
      },
      "id": "3m5EoTQMu3MZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"the king has forbidden me to marry another husband am not i shall ride upon\"\n",
            "[1] \"spread the jam over it spread its wings and crying here comes our hobblety jib\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
      "metadata": {
        "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc"
      },
      "source": [
        "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2025)\n",
        "\n",
        "urlques2b <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
        "tblques2b <- digest_url(urlques2b, n=3)\n",
        "genques2b <- make_ngram_generator(tblques2b, n=3)\n",
        "\n",
        "\n",
        "print(genques2b(start_words = c(\"the\", \"king\"),length=15))\n",
        "\n",
        "set.seed(2025)\n",
        "print(genques2b(length=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38fe7bb4-2503-4130-cbc5-2de2f83050a9",
        "id": "ry1h2HdHGXkC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"the king he added to the entire exclusion of the swords were made prisoners the\"\n",
            "[1] \"lamentation de lemburn came forth completely armed after the fashion of this may be seen\"\n"
          ]
        }
      ],
      "id": "ry1h2HdHGXkC"
    },
    {
      "cell_type": "markdown",
      "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
      "metadata": {
        "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc"
      },
      "source": [
        "#### c) Explain in 1-2 sentences the difference in content generated from each source."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the input/previous/reference source text for each example is different (Grimm's Fairy Tales vs. Anicent Armour and Weapons in Europe), the predicted text will be different. This is the case for having both no text (random start word determined by the seed), or having the two words \"the king\" preceeding the prediction."
      ],
      "metadata": {
        "id": "A29mbZdEGvz6"
      },
      "id": "A29mbZdEGvz6"
    },
    {
      "cell_type": "markdown",
      "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
      "metadata": {
        "id": "56e45972-f441-4d07-9073-fcddd6146cbd"
      },
      "source": [
        "## Question 3\n",
        "#### a) What is a language learning model?\n",
        "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) A language learning model is a machine learning model which predicts the probability of a sequence of words to understand and generate human language. Essentially, it is a probablity distribution over words, given some input of text/words as \"previous words\", it will predicting the next word.\n",
        "\n",
        "b) To run a language model locally, you must install the model (example: OLLAMA) to your device, run the model API server, use functions for POST wrapper, chat completion, and factory, then run it."
      ],
      "metadata": {
        "id": "JilSnudovbTF"
      },
      "id": "JilSnudovbTF"
    },
    {
      "cell_type": "markdown",
      "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
      "metadata": {
        "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8"
      },
      "source": [
        "## Question 4\n",
        "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
        "| Term | Meaning |  \n",
        "|------|---------|\n",
        "| **Shell** | The shell is the program that receives the bytes of 'mkdir project' and interprets them as a command, allowing us to interact with them.|\n",
        "| **Terminal emulator** | The host to the shell, it's the place that the shell sits and runs from. It displays the bytes from the shell in different colors, images, animations, etc. |\n",
        "| **Process** | Something running on the computer. In this case, the mkdir program is the process that runs, executes, and ends.|\n",
        "| **Signal** | When we type mkdir, we send a signal to the process that runs the mkdir program. Something we send to a process to tell it to do something. |\n",
        "| **Standard input** |The component of our process that is able to read the characters in \"mkdir project\" and understand what it means.  |\n",
        "| **Standard output** |The text that is written as an output of the process that executes our \"mkdir project\" input. Sometimes, there is no output, it just runs.  |\n",
        "| **Command line argument** |In this case, \"project\" is the command line argument. mkdir is the process, and \"project\" is the argument that tells it what directory to create |\n",
        "| **The environment** | Everything that the process (mkdir) can see when it is running, including variables and settings.  |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
      "metadata": {
        "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2"
      },
      "source": [
        "## Question 5\n",
        "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
        "#### a) What are the programs?\n",
        "#### b) Explain what this command is doing, part by part."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) The programs in the command are find, xargs, and grep\n",
        "\n",
        "b)find is a program that searches for files, and . lets the find program know to look in the present working directory.\n",
        "\n",
        "xargs is used to basically pipe the output of the first program (all of the R files that match the find program) and puts it into the command line of the second command, rather than the standard input. We're passing not just the names of each .R file to \"grep\", but the contents of the files themselves to grep.\n",
        "\n",
        "grep allows us to search for things within files themselves. We use grep read_csv to search for matches of the read_csv within each .R file that was selected from the working directory in the initial find program."
      ],
      "metadata": {
        "id": "1v2GQ0U4HK8w"
      },
      "id": "1v2GQ0U4HK8w"
    },
    {
      "cell_type": "markdown",
      "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
      "metadata": {
        "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095"
      },
      "source": [
        "## Question 6\n",
        "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions.\n",
        "#### a) Show the response when you run `docker run hello-world`.\n",
        "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
        "#### c) How do you log in to the RStudio server?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) After running docker run hello-world, this was the response:\n",
        "Unable to find image 'hello-world:latest' locally\n",
        "latest: Pulling from library/hello-world\n",
        "17eec7bbc9d7: Pull complete\n",
        "Digest: sha256:f7931603f70e13dbd844253370742c4fc4202d290c80442b2e68706d8f33ce26\n",
        "Status: Downloaded newer image for hello-world:latest\n",
        "\n",
        "Hello from Docker!\n",
        "This message shows that your installation appears to be working correctly.\n",
        "\n",
        "To generate this message, Docker took the following steps:\n",
        " 1. The Docker client contacted the Docker daemon.\n",
        " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
        "    (amd64)\n",
        " 3. The Docker daemon created a new container from that image which runs the\n",
        "    executable that produces the output you are currently reading.\n",
        " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
        "    to your terminal.\n",
        "\n",
        "To try something more ambitious, you can run an Ubuntu container with:\n",
        " $ docker run -it ubuntu bash\n",
        "\n",
        "Share images, automate workflows, and more with a free Docker ID:\n",
        " https://hub.docker.com/\n",
        "\n",
        "For more examples and ideas, visit:\n",
        " https://docs.docker.com/get-started/"
      ],
      "metadata": {
        "id": "clxCid1XtZJ_"
      },
      "id": "clxCid1XtZJ_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Command:  \n",
        "docker run -d -p 8787:8787 -e bios512a10o90210=mypassword rocker/rstudio\n",
        "\n",
        "Output:  \n",
        "Unable to find image 'rocker/rstudio:latest' locally\n",
        "latest: Pulling from rocker/rstudio\n",
        "3665120d345d: Pull complete\n",
        "3c7cdccc4be7: Pull complete\n",
        "664fb1818bbb: Pull complete\n",
        "62f215ca34c6: Pull complete\n",
        "e4b9e87bb831: Pull complete\n",
        "5d246ec925db: Pull complete\n",
        "2c9ba66d5dbe: Pull complete\n",
        "39038e16d1ba: Pull complete\n",
        "191985778909: Pull complete\n",
        "d923cf803a12: Pull complete\n",
        "2a63ed8b2250: Pull complete\n",
        "4b3ffd8ccb52: Pull complete\n",
        "890065c4c99d: Pull complete\n",
        "999e4b8f7ed8: Pull complete\n",
        "9c1a4a0706b7: Pull complete\n",
        "b71e78fefbbb: Pull complete\n",
        "971ba7cf0d8a: Pull complete\n",
        "08e74fd5985d: Pull complete\n",
        "Digest: sha256:9f85211a666fb426081a6f5a01f9f9f51655262258419fa21e0ce38a5afc78d8\n",
        "Status: Downloaded newer image for rocker/rstudio:latest\n",
        "781ee025af1a3cb5682b5e36af44cd006c5329174454debb08844d323daa3042"
      ],
      "metadata": {
        "id": "Z9Sfc0dYtoYU"
      },
      "id": "Z9Sfc0dYtoYU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) To login to the Rstudio server, you would simply type the following into your web browser:  \n",
        "http://localhost:8787\n",
        "\n",
        "The username will be rstudio, and the password will be the one that I assigned in the previous step."
      ],
      "metadata": {
        "id": "cFeBgCAevnJj"
      },
      "id": "cFeBgCAevnJj"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}